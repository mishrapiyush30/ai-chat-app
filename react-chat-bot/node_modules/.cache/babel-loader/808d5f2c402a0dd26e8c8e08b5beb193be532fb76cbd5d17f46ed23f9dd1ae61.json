{"ast":null,"code":"import axios from 'axios';\n\n// API URL - replace with your Flask backend URL or use a proxy in package.json\nconst API_URL = '/api';\n\n// Message interface\n\n// Metrics interface\n\n// API response interface\n\n// Create a new axios instance\nconst api = axios.create({\n  baseURL: API_URL,\n  headers: {\n    'Content-Type': 'application/json'\n  }\n});\n\n// Function to stream chat completions\nexport const streamChatCompletion = async (messages, model = 'gpt-3.5-turbo', onData, onError, onComplete) => {\n  try {\n    var _response$body;\n    const response = await fetch(`${API_URL}/api/chat`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        messages,\n        model,\n        stream: true\n      })\n    });\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n    const reader = (_response$body = response.body) === null || _response$body === void 0 ? void 0 : _response$body.getReader();\n    const decoder = new TextDecoder();\n    if (!reader) {\n      throw new Error('Response body is null');\n    }\n    while (true) {\n      const {\n        value,\n        done\n      } = await reader.read();\n      if (done) break;\n      const chunk = decoder.decode(value, {\n        stream: true\n      });\n      const lines = chunk.split('\\n\\n');\n      for (const line of lines) {\n        if (line.startsWith('data: ')) {\n          try {\n            const data = JSON.parse(line.substring(6));\n            if (data.error) {\n              onError(new Error(data.content));\n              break;\n            } else if (data.done) {\n              if (data.metrics) {\n                onComplete(data.metrics);\n              } else {\n                onComplete();\n              }\n            } else if (data.content) {\n              onData(data);\n            }\n          } catch (e) {\n            console.error('Error parsing SSE data:', e);\n          }\n        }\n      }\n    }\n  } catch (error) {\n    onError(error);\n  }\n};\nexport const sendMessage = async (messages, model, temperature, maxTokens, onChunk, onComplete) => {\n  try {\n    const response = await fetch(`${API_URL}/chat`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        messages,\n        model,\n        temperature,\n        max_tokens: maxTokens,\n        stream: true\n      })\n    });\n    if (!response.ok) {\n      const errorText = await response.text();\n      throw new Error(`API error: ${response.status} - ${errorText}`);\n    }\n    if (!response.body) {\n      throw new Error('ReadableStream not supported');\n    }\n    const reader = response.body.getReader();\n    const decoder = new TextDecoder();\n    let buffer = '';\n    let metrics = null;\n    const processStream = async () => {\n      while (true) {\n        const {\n          done,\n          value\n        } = await reader.read();\n        if (done) break;\n        const chunk = decoder.decode(value, {\n          stream: true\n        });\n        buffer += chunk;\n\n        // Process complete JSON objects from the buffer\n        let startIdx = 0;\n        let endIdx = buffer.indexOf('\\n', startIdx);\n        while (endIdx !== -1) {\n          const line = buffer.substring(startIdx, endIdx).trim();\n          startIdx = endIdx + 1;\n          if (line.startsWith('data: ')) {\n            const jsonStr = line.slice(6);\n            if (jsonStr === '[DONE]') {\n              // Stream is done\n              break;\n            }\n            try {\n              var _data$choices$, _data$choices$$delta;\n              const data = JSON.parse(jsonStr);\n              if (data.choices && (_data$choices$ = data.choices[0]) !== null && _data$choices$ !== void 0 && (_data$choices$$delta = _data$choices$.delta) !== null && _data$choices$$delta !== void 0 && _data$choices$$delta.content) {\n                onChunk(data.choices[0].delta.content);\n              } else if (data.metrics) {\n                metrics = data.metrics;\n              }\n            } catch (err) {\n              console.error('Error parsing JSON:', err);\n            }\n          }\n          endIdx = buffer.indexOf('\\n', startIdx);\n        }\n\n        // Keep the unprocessed part of the buffer\n        buffer = buffer.substring(startIdx);\n      }\n      if (metrics) {\n        onComplete(metrics);\n      }\n    };\n    await processStream();\n  } catch (error) {\n    console.error('Error in sendMessage:', error);\n    throw error;\n  }\n};\nexport const getAvailableModels = async () => {\n  try {\n    const response = await axios.get(`${API_URL}/models`);\n    return response.data.models;\n  } catch (error) {\n    console.error('Error fetching models:', error);\n    return ['gpt-3.5-turbo']; // Fallback to default model\n  }\n};\nexport default api;","map":{"version":3,"names":["axios","API_URL","api","create","baseURL","headers","streamChatCompletion","messages","model","onData","onError","onComplete","_response$body","response","fetch","method","body","JSON","stringify","stream","ok","Error","status","reader","getReader","decoder","TextDecoder","value","done","read","chunk","decode","lines","split","line","startsWith","data","parse","substring","error","content","metrics","e","console","sendMessage","temperature","maxTokens","onChunk","max_tokens","errorText","text","buffer","processStream","startIdx","endIdx","indexOf","trim","jsonStr","slice","_data$choices$","_data$choices$$delta","choices","delta","err","getAvailableModels","get","models"],"sources":["/Users/piyushmishra/Documents/codebase/chat-bot/react-chat-bot/src/services/api.ts"],"sourcesContent":["import axios from 'axios';\n\n// API URL - replace with your Flask backend URL or use a proxy in package.json\nconst API_URL = '/api';\n\n// Message interface\nexport interface Message {\n  role: 'user' | 'assistant' | 'system';\n  content: string;\n}\n\n// Metrics interface\nexport interface Metrics {\n  prompt_tokens: number;\n  completion_tokens: number;\n  total_tokens: number;\n  latency: number;\n  cost: number;\n}\n\n// API response interface\nexport interface ApiResponse {\n  content: string;\n  done?: boolean;\n  error?: boolean;\n  metrics?: Metrics;\n}\n\n// Create a new axios instance\nconst api = axios.create({\n  baseURL: API_URL,\n  headers: {\n    'Content-Type': 'application/json',\n  },\n});\n\n// Function to stream chat completions\nexport const streamChatCompletion = async (\n  messages: Message[],\n  model: string = 'gpt-3.5-turbo',\n  onData: (data: ApiResponse) => void,\n  onError: (error: any) => void,\n  onComplete: (metrics?: Metrics) => void\n) => {\n  try {\n    const response = await fetch(`${API_URL}/api/chat`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        messages,\n        model,\n        stream: true,\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    const reader = response.body?.getReader();\n    const decoder = new TextDecoder();\n\n    if (!reader) {\n      throw new Error('Response body is null');\n    }\n\n    while (true) {\n      const { value, done } = await reader.read();\n      if (done) break;\n\n      const chunk = decoder.decode(value, { stream: true });\n      const lines = chunk.split('\\n\\n');\n\n      for (const line of lines) {\n        if (line.startsWith('data: ')) {\n          try {\n            const data = JSON.parse(line.substring(6)) as ApiResponse;\n            \n            if (data.error) {\n              onError(new Error(data.content));\n              break;\n            } else if (data.done) {\n              if (data.metrics) {\n                onComplete(data.metrics);\n              } else {\n                onComplete();\n              }\n            } else if (data.content) {\n              onData(data);\n            }\n          } catch (e) {\n            console.error('Error parsing SSE data:', e);\n          }\n        }\n      }\n    }\n  } catch (error) {\n    onError(error);\n  }\n};\n\nexport interface ChatRequest {\n  messages: Message[];\n  model: string;\n  temperature: number;\n  max_tokens: number;\n  stream: boolean;\n}\n\nexport interface TokenMetrics {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  estimatedCost: number;\n  latency?: number;\n}\n\nexport const sendMessage = async (\n  messages: Message[],\n  model: string,\n  temperature: number,\n  maxTokens: number,\n  onChunk: (chunk: string) => void,\n  onComplete: (metrics: TokenMetrics) => void\n) => {\n  try {\n    const response = await fetch(`${API_URL}/chat`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        messages,\n        model,\n        temperature,\n        max_tokens: maxTokens,\n        stream: true,\n      }),\n    });\n\n    if (!response.ok) {\n      const errorText = await response.text();\n      throw new Error(`API error: ${response.status} - ${errorText}`);\n    }\n\n    if (!response.body) {\n      throw new Error('ReadableStream not supported');\n    }\n\n    const reader = response.body.getReader();\n    const decoder = new TextDecoder();\n    let buffer = '';\n    let metrics: TokenMetrics | null = null;\n\n    const processStream = async () => {\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        const chunk = decoder.decode(value, { stream: true });\n        buffer += chunk;\n\n        // Process complete JSON objects from the buffer\n        let startIdx = 0;\n        let endIdx = buffer.indexOf('\\n', startIdx);\n\n        while (endIdx !== -1) {\n          const line = buffer.substring(startIdx, endIdx).trim();\n          startIdx = endIdx + 1;\n\n          if (line.startsWith('data: ')) {\n            const jsonStr = line.slice(6);\n            \n            if (jsonStr === '[DONE]') {\n              // Stream is done\n              break;\n            }\n\n            try {\n              const data = JSON.parse(jsonStr);\n              \n              if (data.choices && data.choices[0]?.delta?.content) {\n                onChunk(data.choices[0].delta.content);\n              } else if (data.metrics) {\n                metrics = data.metrics;\n              }\n            } catch (err) {\n              console.error('Error parsing JSON:', err);\n            }\n          }\n\n          endIdx = buffer.indexOf('\\n', startIdx);\n        }\n\n        // Keep the unprocessed part of the buffer\n        buffer = buffer.substring(startIdx);\n      }\n\n      if (metrics) {\n        onComplete(metrics);\n      }\n    };\n\n    await processStream();\n  } catch (error) {\n    console.error('Error in sendMessage:', error);\n    throw error;\n  }\n};\n\nexport const getAvailableModels = async () => {\n  try {\n    const response = await axios.get(`${API_URL}/models`);\n    return response.data.models;\n  } catch (error) {\n    console.error('Error fetching models:', error);\n    return ['gpt-3.5-turbo']; // Fallback to default model\n  }\n};\n\nexport default api; "],"mappings":"AAAA,OAAOA,KAAK,MAAM,OAAO;;AAEzB;AACA,MAAMC,OAAO,GAAG,MAAM;;AAEtB;;AAMA;;AASA;;AAQA;AACA,MAAMC,GAAG,GAAGF,KAAK,CAACG,MAAM,CAAC;EACvBC,OAAO,EAAEH,OAAO;EAChBI,OAAO,EAAE;IACP,cAAc,EAAE;EAClB;AACF,CAAC,CAAC;;AAEF;AACA,OAAO,MAAMC,oBAAoB,GAAG,MAAAA,CAClCC,QAAmB,EACnBC,KAAa,GAAG,eAAe,EAC/BC,MAAmC,EACnCC,OAA6B,EAC7BC,UAAuC,KACpC;EACH,IAAI;IAAA,IAAAC,cAAA;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAGb,OAAO,WAAW,EAAE;MAClDc,MAAM,EAAE,MAAM;MACdV,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDW,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBX,QAAQ;QACRC,KAAK;QACLW,MAAM,EAAE;MACV,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACN,QAAQ,CAACO,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,uBAAuBR,QAAQ,CAACS,MAAM,EAAE,CAAC;IAC3D;IAEA,MAAMC,MAAM,IAAAX,cAAA,GAAGC,QAAQ,CAACG,IAAI,cAAAJ,cAAA,uBAAbA,cAAA,CAAeY,SAAS,CAAC,CAAC;IACzC,MAAMC,OAAO,GAAG,IAAIC,WAAW,CAAC,CAAC;IAEjC,IAAI,CAACH,MAAM,EAAE;MACX,MAAM,IAAIF,KAAK,CAAC,uBAAuB,CAAC;IAC1C;IAEA,OAAO,IAAI,EAAE;MACX,MAAM;QAAEM,KAAK;QAAEC;MAAK,CAAC,GAAG,MAAML,MAAM,CAACM,IAAI,CAAC,CAAC;MAC3C,IAAID,IAAI,EAAE;MAEV,MAAME,KAAK,GAAGL,OAAO,CAACM,MAAM,CAACJ,KAAK,EAAE;QAAER,MAAM,EAAE;MAAK,CAAC,CAAC;MACrD,MAAMa,KAAK,GAAGF,KAAK,CAACG,KAAK,CAAC,MAAM,CAAC;MAEjC,KAAK,MAAMC,IAAI,IAAIF,KAAK,EAAE;QACxB,IAAIE,IAAI,CAACC,UAAU,CAAC,QAAQ,CAAC,EAAE;UAC7B,IAAI;YACF,MAAMC,IAAI,GAAGnB,IAAI,CAACoB,KAAK,CAACH,IAAI,CAACI,SAAS,CAAC,CAAC,CAAC,CAAgB;YAEzD,IAAIF,IAAI,CAACG,KAAK,EAAE;cACd7B,OAAO,CAAC,IAAIW,KAAK,CAACe,IAAI,CAACI,OAAO,CAAC,CAAC;cAChC;YACF,CAAC,MAAM,IAAIJ,IAAI,CAACR,IAAI,EAAE;cACpB,IAAIQ,IAAI,CAACK,OAAO,EAAE;gBAChB9B,UAAU,CAACyB,IAAI,CAACK,OAAO,CAAC;cAC1B,CAAC,MAAM;gBACL9B,UAAU,CAAC,CAAC;cACd;YACF,CAAC,MAAM,IAAIyB,IAAI,CAACI,OAAO,EAAE;cACvB/B,MAAM,CAAC2B,IAAI,CAAC;YACd;UACF,CAAC,CAAC,OAAOM,CAAC,EAAE;YACVC,OAAO,CAACJ,KAAK,CAAC,yBAAyB,EAAEG,CAAC,CAAC;UAC7C;QACF;MACF;IACF;EACF,CAAC,CAAC,OAAOH,KAAK,EAAE;IACd7B,OAAO,CAAC6B,KAAK,CAAC;EAChB;AACF,CAAC;AAkBD,OAAO,MAAMK,WAAW,GAAG,MAAAA,CACzBrC,QAAmB,EACnBC,KAAa,EACbqC,WAAmB,EACnBC,SAAiB,EACjBC,OAAgC,EAChCpC,UAA2C,KACxC;EACH,IAAI;IACF,MAAME,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAGb,OAAO,OAAO,EAAE;MAC9Cc,MAAM,EAAE,MAAM;MACdV,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDW,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBX,QAAQ;QACRC,KAAK;QACLqC,WAAW;QACXG,UAAU,EAAEF,SAAS;QACrB3B,MAAM,EAAE;MACV,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACN,QAAQ,CAACO,EAAE,EAAE;MAChB,MAAM6B,SAAS,GAAG,MAAMpC,QAAQ,CAACqC,IAAI,CAAC,CAAC;MACvC,MAAM,IAAI7B,KAAK,CAAC,cAAcR,QAAQ,CAACS,MAAM,MAAM2B,SAAS,EAAE,CAAC;IACjE;IAEA,IAAI,CAACpC,QAAQ,CAACG,IAAI,EAAE;MAClB,MAAM,IAAIK,KAAK,CAAC,8BAA8B,CAAC;IACjD;IAEA,MAAME,MAAM,GAAGV,QAAQ,CAACG,IAAI,CAACQ,SAAS,CAAC,CAAC;IACxC,MAAMC,OAAO,GAAG,IAAIC,WAAW,CAAC,CAAC;IACjC,IAAIyB,MAAM,GAAG,EAAE;IACf,IAAIV,OAA4B,GAAG,IAAI;IAEvC,MAAMW,aAAa,GAAG,MAAAA,CAAA,KAAY;MAChC,OAAO,IAAI,EAAE;QACX,MAAM;UAAExB,IAAI;UAAED;QAAM,CAAC,GAAG,MAAMJ,MAAM,CAACM,IAAI,CAAC,CAAC;QAC3C,IAAID,IAAI,EAAE;QAEV,MAAME,KAAK,GAAGL,OAAO,CAACM,MAAM,CAACJ,KAAK,EAAE;UAAER,MAAM,EAAE;QAAK,CAAC,CAAC;QACrDgC,MAAM,IAAIrB,KAAK;;QAEf;QACA,IAAIuB,QAAQ,GAAG,CAAC;QAChB,IAAIC,MAAM,GAAGH,MAAM,CAACI,OAAO,CAAC,IAAI,EAAEF,QAAQ,CAAC;QAE3C,OAAOC,MAAM,KAAK,CAAC,CAAC,EAAE;UACpB,MAAMpB,IAAI,GAAGiB,MAAM,CAACb,SAAS,CAACe,QAAQ,EAAEC,MAAM,CAAC,CAACE,IAAI,CAAC,CAAC;UACtDH,QAAQ,GAAGC,MAAM,GAAG,CAAC;UAErB,IAAIpB,IAAI,CAACC,UAAU,CAAC,QAAQ,CAAC,EAAE;YAC7B,MAAMsB,OAAO,GAAGvB,IAAI,CAACwB,KAAK,CAAC,CAAC,CAAC;YAE7B,IAAID,OAAO,KAAK,QAAQ,EAAE;cACxB;cACA;YACF;YAEA,IAAI;cAAA,IAAAE,cAAA,EAAAC,oBAAA;cACF,MAAMxB,IAAI,GAAGnB,IAAI,CAACoB,KAAK,CAACoB,OAAO,CAAC;cAEhC,IAAIrB,IAAI,CAACyB,OAAO,KAAAF,cAAA,GAAIvB,IAAI,CAACyB,OAAO,CAAC,CAAC,CAAC,cAAAF,cAAA,gBAAAC,oBAAA,GAAfD,cAAA,CAAiBG,KAAK,cAAAF,oBAAA,eAAtBA,oBAAA,CAAwBpB,OAAO,EAAE;gBACnDO,OAAO,CAACX,IAAI,CAACyB,OAAO,CAAC,CAAC,CAAC,CAACC,KAAK,CAACtB,OAAO,CAAC;cACxC,CAAC,MAAM,IAAIJ,IAAI,CAACK,OAAO,EAAE;gBACvBA,OAAO,GAAGL,IAAI,CAACK,OAAO;cACxB;YACF,CAAC,CAAC,OAAOsB,GAAG,EAAE;cACZpB,OAAO,CAACJ,KAAK,CAAC,qBAAqB,EAAEwB,GAAG,CAAC;YAC3C;UACF;UAEAT,MAAM,GAAGH,MAAM,CAACI,OAAO,CAAC,IAAI,EAAEF,QAAQ,CAAC;QACzC;;QAEA;QACAF,MAAM,GAAGA,MAAM,CAACb,SAAS,CAACe,QAAQ,CAAC;MACrC;MAEA,IAAIZ,OAAO,EAAE;QACX9B,UAAU,CAAC8B,OAAO,CAAC;MACrB;IACF,CAAC;IAED,MAAMW,aAAa,CAAC,CAAC;EACvB,CAAC,CAAC,OAAOb,KAAK,EAAE;IACdI,OAAO,CAACJ,KAAK,CAAC,uBAAuB,EAAEA,KAAK,CAAC;IAC7C,MAAMA,KAAK;EACb;AACF,CAAC;AAED,OAAO,MAAMyB,kBAAkB,GAAG,MAAAA,CAAA,KAAY;EAC5C,IAAI;IACF,MAAMnD,QAAQ,GAAG,MAAMb,KAAK,CAACiE,GAAG,CAAC,GAAGhE,OAAO,SAAS,CAAC;IACrD,OAAOY,QAAQ,CAACuB,IAAI,CAAC8B,MAAM;EAC7B,CAAC,CAAC,OAAO3B,KAAK,EAAE;IACdI,OAAO,CAACJ,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC;IAC9C,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC;EAC5B;AACF,CAAC;AAED,eAAerC,GAAG","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}