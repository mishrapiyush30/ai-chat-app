{"ast":null,"code":"var _jsxFileName = \"/Users/piyushmishra/Documents/codebase/chat-bot/react-chat-bot/src/context/ChatContext.tsx\",\n  _s = $RefreshSig$(),\n  _s2 = $RefreshSig$();\nimport React, { createContext, useContext, useState, useEffect } from 'react';\nimport { sendMessage, getAvailableModels } from '../services/api';\n\n// Prompt templates\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport const PROMPT_TEMPLATES = {\n  GENERAL: {\n    name: 'General',\n    content: 'You are a helpful AI assistant. Answer the following question or respond to the following request:'\n  },\n  ELI5: {\n    name: 'Explain Like I\\'m 5',\n    content: 'You are a helpful AI assistant. Explain the following concept in simple terms that a 5-year-old would understand:'\n  },\n  SUMMARIZE: {\n    name: 'Summarize',\n    content: 'You are a helpful AI assistant. Summarize the following text concisely while retaining the key points:'\n  }\n};\nconst ChatContext = /*#__PURE__*/createContext(undefined);\nexport const ChatProvider = ({\n  children\n}) => {\n  _s();\n  const [messages, setMessages] = useState([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const [metrics, setMetrics] = useState(null);\n  const [models, setModels] = useState(['gpt-3.5-turbo']);\n  const [selectedModel, setSelectedModel] = useState('gpt-3.5-turbo');\n  const [temperature, setTemperature] = useState(0.7);\n  const [maxTokens, setMaxTokens] = useState(1000);\n  const [activePromptTemplate, setActivePromptTemplate] = useState('GENERAL');\n\n  // Load messages from localStorage on component mount\n  useEffect(() => {\n    const savedMessages = localStorage.getItem('chatMessages');\n    if (savedMessages) {\n      try {\n        setMessages(JSON.parse(savedMessages));\n      } catch (err) {\n        console.error('Error parsing saved messages:', err);\n      }\n    }\n\n    // Fetch available models\n    getAvailableModels().then(availableModels => {\n      setModels(availableModels);\n      // Set default model to GPT-4 if available, otherwise use GPT-3.5\n      if (availableModels.includes('gpt-4')) {\n        setSelectedModel('gpt-4');\n      }\n    }).catch(err => {\n      console.error('Error fetching models:', err);\n    });\n  }, []);\n\n  // Save messages to localStorage whenever they change\n  useEffect(() => {\n    // Keep only the last 8 messages to avoid localStorage size limits\n    const messagesToSave = messages.slice(-8);\n    localStorage.setItem('chatMessages', JSON.stringify(messagesToSave));\n  }, [messages]);\n  const sendUserMessage = async content => {\n    try {\n      setError(null);\n      setIsLoading(true);\n\n      // Add system message with the selected prompt template\n      const systemMessage = {\n        role: 'system',\n        content: PROMPT_TEMPLATES[activePromptTemplate].content\n      };\n\n      // Add user message\n      const userMessage = {\n        role: 'user',\n        content\n      };\n\n      // Create a temporary assistant message for streaming\n      const tempAssistantMessage = {\n        role: 'assistant',\n        content: ''\n      };\n\n      // Update messages state with system, user, and empty assistant message\n      setMessages(prev => [...prev, userMessage, tempAssistantMessage]);\n\n      // Prepare messages for API call\n      const apiMessages = [systemMessage, ...messages.slice(-6),\n      // Include recent context (last 6 messages)\n      userMessage];\n      let responseContent = '';\n\n      // Send the request to the API\n      await sendMessage(apiMessages, selectedModel, temperature, maxTokens, chunk => {\n        // Update the assistant message content as chunks arrive\n        responseContent += chunk;\n        setMessages(prev => {\n          const updated = [...prev];\n          updated[updated.length - 1] = {\n            ...updated[updated.length - 1],\n            content: responseContent\n          };\n          return updated;\n        });\n      }, newMetrics => {\n        // Update metrics when complete\n        setMetrics(newMetrics);\n      });\n    } catch (err) {\n      console.error('Error sending message:', err);\n      setError(err instanceof Error ? err.message : 'An unknown error occurred');\n\n      // Update the assistant message with the error\n      setMessages(prev => {\n        const updated = [...prev];\n        if (updated.length > 0 && updated[updated.length - 1].role === 'assistant') {\n          updated[updated.length - 1] = {\n            ...updated[updated.length - 1],\n            content: 'Sorry, an error occurred while processing your request. Please try again.'\n          };\n        }\n        return updated;\n      });\n    } finally {\n      setIsLoading(false);\n    }\n  };\n  const clearChat = () => {\n    setMessages([]);\n    setMetrics(null);\n    setError(null);\n  };\n  const value = {\n    messages,\n    isLoading,\n    error,\n    metrics,\n    models,\n    selectedModel,\n    temperature,\n    maxTokens,\n    activePromptTemplate,\n    sendUserMessage,\n    clearChat,\n    setSelectedModel,\n    setTemperature,\n    setMaxTokens,\n    setActivePromptTemplate\n  };\n  return /*#__PURE__*/_jsxDEV(ChatContext.Provider, {\n    value: value,\n    children: children\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 184,\n    columnNumber: 10\n  }, this);\n};\n_s(ChatProvider, \"OdHr5PQ/gSgjMlR/o1Wvt6XCYas=\");\n_c = ChatProvider;\nexport const useChatContext = () => {\n  _s2();\n  const context = useContext(ChatContext);\n  if (context === undefined) {\n    throw new Error('useChatContext must be used within a ChatProvider');\n  }\n  return context;\n};\n_s2(useChatContext, \"b9L3QQ+jgeyIrH0NfHrJ8nn7VMU=\");\nvar _c;\n$RefreshReg$(_c, \"ChatProvider\");","map":{"version":3,"names":["React","createContext","useContext","useState","useEffect","sendMessage","getAvailableModels","jsxDEV","_jsxDEV","PROMPT_TEMPLATES","GENERAL","name","content","ELI5","SUMMARIZE","ChatContext","undefined","ChatProvider","children","_s","messages","setMessages","isLoading","setIsLoading","error","setError","metrics","setMetrics","models","setModels","selectedModel","setSelectedModel","temperature","setTemperature","maxTokens","setMaxTokens","activePromptTemplate","setActivePromptTemplate","savedMessages","localStorage","getItem","JSON","parse","err","console","then","availableModels","includes","catch","messagesToSave","slice","setItem","stringify","sendUserMessage","systemMessage","role","userMessage","tempAssistantMessage","prev","apiMessages","responseContent","chunk","updated","length","newMetrics","Error","message","clearChat","value","Provider","fileName","_jsxFileName","lineNumber","columnNumber","_c","useChatContext","_s2","context","$RefreshReg$"],"sources":["/Users/piyushmishra/Documents/codebase/chat-bot/react-chat-bot/src/context/ChatContext.tsx"],"sourcesContent":["import React, { createContext, useContext, useState, useEffect, ReactNode } from 'react';\nimport { Message, TokenMetrics, sendMessage, getAvailableModels } from '../services/api';\n\n// Prompt templates\nexport const PROMPT_TEMPLATES = {\n  GENERAL: {\n    name: 'General',\n    content: 'You are a helpful AI assistant. Answer the following question or respond to the following request:'\n  },\n  ELI5: {\n    name: 'Explain Like I\\'m 5',\n    content: 'You are a helpful AI assistant. Explain the following concept in simple terms that a 5-year-old would understand:'\n  },\n  SUMMARIZE: {\n    name: 'Summarize',\n    content: 'You are a helpful AI assistant. Summarize the following text concisely while retaining the key points:'\n  }\n};\n\ninterface ChatContextType {\n  messages: Message[];\n  isLoading: boolean;\n  error: string | null;\n  metrics: TokenMetrics | null;\n  models: string[];\n  selectedModel: string;\n  temperature: number;\n  maxTokens: number;\n  activePromptTemplate: keyof typeof PROMPT_TEMPLATES;\n  sendUserMessage: (content: string) => Promise<void>;\n  clearChat: () => void;\n  setSelectedModel: (model: string) => void;\n  setTemperature: (temp: number) => void;\n  setMaxTokens: (tokens: number) => void;\n  setActivePromptTemplate: (template: keyof typeof PROMPT_TEMPLATES) => void;\n}\n\nconst ChatContext = createContext<ChatContextType | undefined>(undefined);\n\ninterface ChatProviderProps {\n  children: ReactNode;\n}\n\nexport const ChatProvider: React.FC<ChatProviderProps> = ({ children }) => {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n  const [metrics, setMetrics] = useState<TokenMetrics | null>(null);\n  const [models, setModels] = useState<string[]>(['gpt-3.5-turbo']);\n  const [selectedModel, setSelectedModel] = useState('gpt-3.5-turbo');\n  const [temperature, setTemperature] = useState(0.7);\n  const [maxTokens, setMaxTokens] = useState(1000);\n  const [activePromptTemplate, setActivePromptTemplate] = useState<keyof typeof PROMPT_TEMPLATES>('GENERAL');\n\n  // Load messages from localStorage on component mount\n  useEffect(() => {\n    const savedMessages = localStorage.getItem('chatMessages');\n    if (savedMessages) {\n      try {\n        setMessages(JSON.parse(savedMessages));\n      } catch (err) {\n        console.error('Error parsing saved messages:', err);\n      }\n    }\n\n    // Fetch available models\n    getAvailableModels()\n      .then(availableModels => {\n        setModels(availableModels);\n        // Set default model to GPT-4 if available, otherwise use GPT-3.5\n        if (availableModels.includes('gpt-4')) {\n          setSelectedModel('gpt-4');\n        }\n      })\n      .catch(err => {\n        console.error('Error fetching models:', err);\n      });\n  }, []);\n\n  // Save messages to localStorage whenever they change\n  useEffect(() => {\n    // Keep only the last 8 messages to avoid localStorage size limits\n    const messagesToSave = messages.slice(-8);\n    localStorage.setItem('chatMessages', JSON.stringify(messagesToSave));\n  }, [messages]);\n\n  const sendUserMessage = async (content: string) => {\n    try {\n      setError(null);\n      setIsLoading(true);\n\n      // Add system message with the selected prompt template\n      const systemMessage: Message = {\n        role: 'system',\n        content: PROMPT_TEMPLATES[activePromptTemplate].content\n      };\n\n      // Add user message\n      const userMessage: Message = { role: 'user', content };\n      \n      // Create a temporary assistant message for streaming\n      const tempAssistantMessage: Message = { role: 'assistant', content: '' };\n      \n      // Update messages state with system, user, and empty assistant message\n      setMessages(prev => [...prev, userMessage, tempAssistantMessage]);\n\n      // Prepare messages for API call\n      const apiMessages = [\n        systemMessage,\n        ...messages.slice(-6), // Include recent context (last 6 messages)\n        userMessage\n      ];\n\n      let responseContent = '';\n\n      // Send the request to the API\n      await sendMessage(\n        apiMessages,\n        selectedModel,\n        temperature,\n        maxTokens,\n        (chunk) => {\n          // Update the assistant message content as chunks arrive\n          responseContent += chunk;\n          setMessages(prev => {\n            const updated = [...prev];\n            updated[updated.length - 1] = {\n              ...updated[updated.length - 1],\n              content: responseContent\n            };\n            return updated;\n          });\n        },\n        (newMetrics) => {\n          // Update metrics when complete\n          setMetrics(newMetrics);\n        }\n      );\n\n    } catch (err) {\n      console.error('Error sending message:', err);\n      setError(err instanceof Error ? err.message : 'An unknown error occurred');\n      \n      // Update the assistant message with the error\n      setMessages(prev => {\n        const updated = [...prev];\n        if (updated.length > 0 && updated[updated.length - 1].role === 'assistant') {\n          updated[updated.length - 1] = {\n            ...updated[updated.length - 1],\n            content: 'Sorry, an error occurred while processing your request. Please try again.'\n          };\n        }\n        return updated;\n      });\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const clearChat = () => {\n    setMessages([]);\n    setMetrics(null);\n    setError(null);\n  };\n\n  const value = {\n    messages,\n    isLoading,\n    error,\n    metrics,\n    models,\n    selectedModel,\n    temperature,\n    maxTokens,\n    activePromptTemplate,\n    sendUserMessage,\n    clearChat,\n    setSelectedModel,\n    setTemperature,\n    setMaxTokens,\n    setActivePromptTemplate\n  };\n\n  return <ChatContext.Provider value={value}>{children}</ChatContext.Provider>;\n};\n\nexport const useChatContext = () => {\n  const context = useContext(ChatContext);\n  if (context === undefined) {\n    throw new Error('useChatContext must be used within a ChatProvider');\n  }\n  return context;\n}; "],"mappings":";;;AAAA,OAAOA,KAAK,IAAIC,aAAa,EAAEC,UAAU,EAAEC,QAAQ,EAAEC,SAAS,QAAmB,OAAO;AACxF,SAAgCC,WAAW,EAAEC,kBAAkB,QAAQ,iBAAiB;;AAExF;AAAA,SAAAC,MAAA,IAAAC,OAAA;AACA,OAAO,MAAMC,gBAAgB,GAAG;EAC9BC,OAAO,EAAE;IACPC,IAAI,EAAE,SAAS;IACfC,OAAO,EAAE;EACX,CAAC;EACDC,IAAI,EAAE;IACJF,IAAI,EAAE,qBAAqB;IAC3BC,OAAO,EAAE;EACX,CAAC;EACDE,SAAS,EAAE;IACTH,IAAI,EAAE,WAAW;IACjBC,OAAO,EAAE;EACX;AACF,CAAC;AAoBD,MAAMG,WAAW,gBAAGd,aAAa,CAA8Be,SAAS,CAAC;AAMzE,OAAO,MAAMC,YAAyC,GAAGA,CAAC;EAAEC;AAAS,CAAC,KAAK;EAAAC,EAAA;EACzE,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGlB,QAAQ,CAAY,EAAE,CAAC;EACvD,MAAM,CAACmB,SAAS,EAAEC,YAAY,CAAC,GAAGpB,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACqB,KAAK,EAAEC,QAAQ,CAAC,GAAGtB,QAAQ,CAAgB,IAAI,CAAC;EACvD,MAAM,CAACuB,OAAO,EAAEC,UAAU,CAAC,GAAGxB,QAAQ,CAAsB,IAAI,CAAC;EACjE,MAAM,CAACyB,MAAM,EAAEC,SAAS,CAAC,GAAG1B,QAAQ,CAAW,CAAC,eAAe,CAAC,CAAC;EACjE,MAAM,CAAC2B,aAAa,EAAEC,gBAAgB,CAAC,GAAG5B,QAAQ,CAAC,eAAe,CAAC;EACnE,MAAM,CAAC6B,WAAW,EAAEC,cAAc,CAAC,GAAG9B,QAAQ,CAAC,GAAG,CAAC;EACnD,MAAM,CAAC+B,SAAS,EAAEC,YAAY,CAAC,GAAGhC,QAAQ,CAAC,IAAI,CAAC;EAChD,MAAM,CAACiC,oBAAoB,EAAEC,uBAAuB,CAAC,GAAGlC,QAAQ,CAAgC,SAAS,CAAC;;EAE1G;EACAC,SAAS,CAAC,MAAM;IACd,MAAMkC,aAAa,GAAGC,YAAY,CAACC,OAAO,CAAC,cAAc,CAAC;IAC1D,IAAIF,aAAa,EAAE;MACjB,IAAI;QACFjB,WAAW,CAACoB,IAAI,CAACC,KAAK,CAACJ,aAAa,CAAC,CAAC;MACxC,CAAC,CAAC,OAAOK,GAAG,EAAE;QACZC,OAAO,CAACpB,KAAK,CAAC,+BAA+B,EAAEmB,GAAG,CAAC;MACrD;IACF;;IAEA;IACArC,kBAAkB,CAAC,CAAC,CACjBuC,IAAI,CAACC,eAAe,IAAI;MACvBjB,SAAS,CAACiB,eAAe,CAAC;MAC1B;MACA,IAAIA,eAAe,CAACC,QAAQ,CAAC,OAAO,CAAC,EAAE;QACrChB,gBAAgB,CAAC,OAAO,CAAC;MAC3B;IACF,CAAC,CAAC,CACDiB,KAAK,CAACL,GAAG,IAAI;MACZC,OAAO,CAACpB,KAAK,CAAC,wBAAwB,EAAEmB,GAAG,CAAC;IAC9C,CAAC,CAAC;EACN,CAAC,EAAE,EAAE,CAAC;;EAEN;EACAvC,SAAS,CAAC,MAAM;IACd;IACA,MAAM6C,cAAc,GAAG7B,QAAQ,CAAC8B,KAAK,CAAC,CAAC,CAAC,CAAC;IACzCX,YAAY,CAACY,OAAO,CAAC,cAAc,EAAEV,IAAI,CAACW,SAAS,CAACH,cAAc,CAAC,CAAC;EACtE,CAAC,EAAE,CAAC7B,QAAQ,CAAC,CAAC;EAEd,MAAMiC,eAAe,GAAG,MAAOzC,OAAe,IAAK;IACjD,IAAI;MACFa,QAAQ,CAAC,IAAI,CAAC;MACdF,YAAY,CAAC,IAAI,CAAC;;MAElB;MACA,MAAM+B,aAAsB,GAAG;QAC7BC,IAAI,EAAE,QAAQ;QACd3C,OAAO,EAAEH,gBAAgB,CAAC2B,oBAAoB,CAAC,CAACxB;MAClD,CAAC;;MAED;MACA,MAAM4C,WAAoB,GAAG;QAAED,IAAI,EAAE,MAAM;QAAE3C;MAAQ,CAAC;;MAEtD;MACA,MAAM6C,oBAA6B,GAAG;QAAEF,IAAI,EAAE,WAAW;QAAE3C,OAAO,EAAE;MAAG,CAAC;;MAExE;MACAS,WAAW,CAACqC,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAEF,WAAW,EAAEC,oBAAoB,CAAC,CAAC;;MAEjE;MACA,MAAME,WAAW,GAAG,CAClBL,aAAa,EACb,GAAGlC,QAAQ,CAAC8B,KAAK,CAAC,CAAC,CAAC,CAAC;MAAE;MACvBM,WAAW,CACZ;MAED,IAAII,eAAe,GAAG,EAAE;;MAExB;MACA,MAAMvD,WAAW,CACfsD,WAAW,EACX7B,aAAa,EACbE,WAAW,EACXE,SAAS,EACR2B,KAAK,IAAK;QACT;QACAD,eAAe,IAAIC,KAAK;QACxBxC,WAAW,CAACqC,IAAI,IAAI;UAClB,MAAMI,OAAO,GAAG,CAAC,GAAGJ,IAAI,CAAC;UACzBI,OAAO,CAACA,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC,GAAG;YAC5B,GAAGD,OAAO,CAACA,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC;YAC9BnD,OAAO,EAAEgD;UACX,CAAC;UACD,OAAOE,OAAO;QAChB,CAAC,CAAC;MACJ,CAAC,EACAE,UAAU,IAAK;QACd;QACArC,UAAU,CAACqC,UAAU,CAAC;MACxB,CACF,CAAC;IAEH,CAAC,CAAC,OAAOrB,GAAG,EAAE;MACZC,OAAO,CAACpB,KAAK,CAAC,wBAAwB,EAAEmB,GAAG,CAAC;MAC5ClB,QAAQ,CAACkB,GAAG,YAAYsB,KAAK,GAAGtB,GAAG,CAACuB,OAAO,GAAG,2BAA2B,CAAC;;MAE1E;MACA7C,WAAW,CAACqC,IAAI,IAAI;QAClB,MAAMI,OAAO,GAAG,CAAC,GAAGJ,IAAI,CAAC;QACzB,IAAII,OAAO,CAACC,MAAM,GAAG,CAAC,IAAID,OAAO,CAACA,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC,CAACR,IAAI,KAAK,WAAW,EAAE;UAC1EO,OAAO,CAACA,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC,GAAG;YAC5B,GAAGD,OAAO,CAACA,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC;YAC9BnD,OAAO,EAAE;UACX,CAAC;QACH;QACA,OAAOkD,OAAO;MAChB,CAAC,CAAC;IACJ,CAAC,SAAS;MACRvC,YAAY,CAAC,KAAK,CAAC;IACrB;EACF,CAAC;EAED,MAAM4C,SAAS,GAAGA,CAAA,KAAM;IACtB9C,WAAW,CAAC,EAAE,CAAC;IACfM,UAAU,CAAC,IAAI,CAAC;IAChBF,QAAQ,CAAC,IAAI,CAAC;EAChB,CAAC;EAED,MAAM2C,KAAK,GAAG;IACZhD,QAAQ;IACRE,SAAS;IACTE,KAAK;IACLE,OAAO;IACPE,MAAM;IACNE,aAAa;IACbE,WAAW;IACXE,SAAS;IACTE,oBAAoB;IACpBiB,eAAe;IACfc,SAAS;IACTpC,gBAAgB;IAChBE,cAAc;IACdE,YAAY;IACZE;EACF,CAAC;EAED,oBAAO7B,OAAA,CAACO,WAAW,CAACsD,QAAQ;IAACD,KAAK,EAAEA,KAAM;IAAAlD,QAAA,EAAEA;EAAQ;IAAAoD,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAAuB,CAAC;AAC9E,CAAC;AAACtD,EAAA,CA7IWF,YAAyC;AAAAyD,EAAA,GAAzCzD,YAAyC;AA+ItD,OAAO,MAAM0D,cAAc,GAAGA,CAAA,KAAM;EAAAC,GAAA;EAClC,MAAMC,OAAO,GAAG3E,UAAU,CAACa,WAAW,CAAC;EACvC,IAAI8D,OAAO,KAAK7D,SAAS,EAAE;IACzB,MAAM,IAAIiD,KAAK,CAAC,mDAAmD,CAAC;EACtE;EACA,OAAOY,OAAO;AAChB,CAAC;AAACD,GAAA,CANWD,cAAc;AAAA,IAAAD,EAAA;AAAAI,YAAA,CAAAJ,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}